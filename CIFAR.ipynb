{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KUSH_BATCH_2_ASSIGNMENT4B.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/kushsharma1001/Deep-Learning/blob/master/CIFAR.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "f7ZVDfQ95-jy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hyS9qxNW6SPS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.layers import Concatenate\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M7sKML2y6SXq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# this part will prevent tensorflow to allocate all the avaliable GPU Memory\n",
        "# backend\n",
        "import tensorflow as tf\n",
        "from keras import backend as k\n",
        "\n",
        "# Don't pre-allocate memory; allocate as-needed\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "\n",
        "# Create a session with the above options specified.\n",
        "k.tensorflow_backend.set_session(tf.Session(config=config))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8uV3URTQ6SgW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 50\n",
        "l = 40\n",
        "num_filter = 24\n",
        "compression = 0.5\n",
        "dropout_rate = 0.2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ib2wx9_36osu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "fb764b97-18ae-498e-cf64-1f9f744cf17c"
      },
      "cell_type": "code",
      "source": [
        "# Load CIFAR10 Data\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "img_height, img_width, channel = x_train.shape[1],x_train.shape[2],x_train.shape[3]\n",
        "\n",
        "#print Input Size\n",
        "print(img_height)\n",
        "print(img_width)\n",
        "print(channel)\n",
        "\n",
        "# convert to one hot encoing \n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32\n",
            "32\n",
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vk5MzV_k6pET",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Dense Block\n",
        "def add_denseblock(input, num_filter = 24, dropout_rate = 0.2):\n",
        "    global compression\n",
        "    temp = input\n",
        "    for _ in range(l):\n",
        "        BatchNorm = BatchNormalization()(temp)\n",
        "        relu = Activation('relu')(BatchNorm)\n",
        "        Conv2D_3_3 = Conv2D(int(num_filter*compression), (3,3), use_bias=False ,padding='same')(relu)\n",
        "        if dropout_rate>0:\n",
        "          Conv2D_3_3 = Dropout(dropout_rate)(Conv2D_3_3)\n",
        "        concat = Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
        "        \n",
        "        temp = concat\n",
        "        \n",
        "    return temp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Sy5ZI_y06pSd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def add_transition(input, num_filter = 24, dropout_rate = 0.2):\n",
        "    global compression\n",
        "    BatchNorm = BatchNormalization()(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "    Conv2D_BottleNeck = Conv2D(int(num_filter*compression), (1,1), use_bias=False ,padding='same')(relu)\n",
        "    if dropout_rate>0:\n",
        "      Conv2D_BottleNeck = Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
        "    avg = AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
        "    \n",
        "    return avg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vDlkbUJl6SpZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def output_layer(input):\n",
        "    global compression\n",
        "    BatchNorm = BatchNormalization()(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "    AvgPooling = AveragePooling2D(pool_size=(2,2))(relu)\n",
        "    flat = Flatten()(AvgPooling)\n",
        "    output = Dense(num_classes, activation='softmax')(flat)\n",
        "    \n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s35Y_4Ip6Sxt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_filter = 24\n",
        "dropout_rate = 0.2\n",
        "l = 12\n",
        "input = Input(shape=(img_height, img_width, channel,))\n",
        "input_new = Conv2D(num_filter, (1,1), use_bias=False, padding='same') (input)\n",
        "input_new2 = Conv2D(num_filter, (3,3), use_bias=False, padding='same') (input_new)\n",
        "\n",
        "First_Conv2D = Conv2D(num_filter, (3,3), use_bias=False ,padding='same')(input_new2)\n",
        "\n",
        "First_Block = add_denseblock(First_Conv2D, num_filter, dropout_rate)\n",
        "First_Transition = add_transition(First_Block, num_filter, dropout_rate)\n",
        "\n",
        "Second_Block = add_denseblock(First_Transition, num_filter, dropout_rate)\n",
        "Second_Transition = add_transition(Second_Block, num_filter, dropout_rate)\n",
        "\n",
        "Third_Block = add_denseblock(Second_Transition, num_filter, dropout_rate)\n",
        "Third_Transition = add_transition(Third_Block, num_filter, dropout_rate)\n",
        "\n",
        "Last_Block = add_denseblock(Third_Transition,  num_filter, dropout_rate)\n",
        "output = output_layer(Last_Block)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IiU19Aqe6S5N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 9928
        },
        "outputId": "afb5de32-6d50-408d-de4b-acda7293c0e3"
      },
      "cell_type": "code",
      "source": [
        "model = Model(inputs=[input], outputs=[output])\n",
        "model.summary()"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_10 (InputLayer)           (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_553 (Conv2D)             (None, 32, 32, 24)   72          input_10[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_554 (Conv2D)             (None, 32, 32, 24)   5184        conv2d_553[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_555 (Conv2D)             (None, 32, 32, 24)   5184        conv2d_554[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_534 (BatchN (None, 32, 32, 24)   96          conv2d_555[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_533 (Activation)     (None, 32, 32, 24)   0           batch_normalization_534[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_556 (Conv2D)             (None, 32, 32, 12)   2592        activation_533[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_525 (Dropout)           (None, 32, 32, 12)   0           conv2d_556[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_500 (Concatenate)   (None, 32, 32, 36)   0           conv2d_555[0][0]                 \n",
            "                                                                 dropout_525[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_535 (BatchN (None, 32, 32, 36)   144         concatenate_500[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_534 (Activation)     (None, 32, 32, 36)   0           batch_normalization_535[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_557 (Conv2D)             (None, 32, 32, 12)   3888        activation_534[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_526 (Dropout)           (None, 32, 32, 12)   0           conv2d_557[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_501 (Concatenate)   (None, 32, 32, 48)   0           concatenate_500[0][0]            \n",
            "                                                                 dropout_526[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_536 (BatchN (None, 32, 32, 48)   192         concatenate_501[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_535 (Activation)     (None, 32, 32, 48)   0           batch_normalization_536[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_558 (Conv2D)             (None, 32, 32, 12)   5184        activation_535[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_527 (Dropout)           (None, 32, 32, 12)   0           conv2d_558[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_502 (Concatenate)   (None, 32, 32, 60)   0           concatenate_501[0][0]            \n",
            "                                                                 dropout_527[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_537 (BatchN (None, 32, 32, 60)   240         concatenate_502[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_536 (Activation)     (None, 32, 32, 60)   0           batch_normalization_537[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_559 (Conv2D)             (None, 32, 32, 12)   6480        activation_536[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_528 (Dropout)           (None, 32, 32, 12)   0           conv2d_559[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_503 (Concatenate)   (None, 32, 32, 72)   0           concatenate_502[0][0]            \n",
            "                                                                 dropout_528[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_538 (BatchN (None, 32, 32, 72)   288         concatenate_503[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_537 (Activation)     (None, 32, 32, 72)   0           batch_normalization_538[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_560 (Conv2D)             (None, 32, 32, 12)   7776        activation_537[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_529 (Dropout)           (None, 32, 32, 12)   0           conv2d_560[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_504 (Concatenate)   (None, 32, 32, 84)   0           concatenate_503[0][0]            \n",
            "                                                                 dropout_529[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_539 (BatchN (None, 32, 32, 84)   336         concatenate_504[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_538 (Activation)     (None, 32, 32, 84)   0           batch_normalization_539[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_561 (Conv2D)             (None, 32, 32, 12)   9072        activation_538[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_530 (Dropout)           (None, 32, 32, 12)   0           conv2d_561[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_505 (Concatenate)   (None, 32, 32, 96)   0           concatenate_504[0][0]            \n",
            "                                                                 dropout_530[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_540 (BatchN (None, 32, 32, 96)   384         concatenate_505[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_539 (Activation)     (None, 32, 32, 96)   0           batch_normalization_540[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_562 (Conv2D)             (None, 32, 32, 12)   10368       activation_539[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_531 (Dropout)           (None, 32, 32, 12)   0           conv2d_562[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_506 (Concatenate)   (None, 32, 32, 108)  0           concatenate_505[0][0]            \n",
            "                                                                 dropout_531[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_541 (BatchN (None, 32, 32, 108)  432         concatenate_506[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_540 (Activation)     (None, 32, 32, 108)  0           batch_normalization_541[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_563 (Conv2D)             (None, 32, 32, 12)   11664       activation_540[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_532 (Dropout)           (None, 32, 32, 12)   0           conv2d_563[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_507 (Concatenate)   (None, 32, 32, 120)  0           concatenate_506[0][0]            \n",
            "                                                                 dropout_532[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_542 (BatchN (None, 32, 32, 120)  480         concatenate_507[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_541 (Activation)     (None, 32, 32, 120)  0           batch_normalization_542[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_564 (Conv2D)             (None, 32, 32, 12)   12960       activation_541[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_533 (Dropout)           (None, 32, 32, 12)   0           conv2d_564[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_508 (Concatenate)   (None, 32, 32, 132)  0           concatenate_507[0][0]            \n",
            "                                                                 dropout_533[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_543 (BatchN (None, 32, 32, 132)  528         concatenate_508[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_542 (Activation)     (None, 32, 32, 132)  0           batch_normalization_543[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_565 (Conv2D)             (None, 32, 32, 12)   14256       activation_542[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_534 (Dropout)           (None, 32, 32, 12)   0           conv2d_565[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_509 (Concatenate)   (None, 32, 32, 144)  0           concatenate_508[0][0]            \n",
            "                                                                 dropout_534[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_544 (BatchN (None, 32, 32, 144)  576         concatenate_509[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_543 (Activation)     (None, 32, 32, 144)  0           batch_normalization_544[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_566 (Conv2D)             (None, 32, 32, 12)   15552       activation_543[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_535 (Dropout)           (None, 32, 32, 12)   0           conv2d_566[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_510 (Concatenate)   (None, 32, 32, 156)  0           concatenate_509[0][0]            \n",
            "                                                                 dropout_535[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_545 (BatchN (None, 32, 32, 156)  624         concatenate_510[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_544 (Activation)     (None, 32, 32, 156)  0           batch_normalization_545[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_567 (Conv2D)             (None, 32, 32, 12)   16848       activation_544[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_536 (Dropout)           (None, 32, 32, 12)   0           conv2d_567[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_511 (Concatenate)   (None, 32, 32, 168)  0           concatenate_510[0][0]            \n",
            "                                                                 dropout_536[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_546 (BatchN (None, 32, 32, 168)  672         concatenate_511[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_545 (Activation)     (None, 32, 32, 168)  0           batch_normalization_546[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_568 (Conv2D)             (None, 32, 32, 12)   2016        activation_545[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_537 (Dropout)           (None, 32, 32, 12)   0           conv2d_568[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_34 (AveragePo (None, 16, 16, 12)   0           dropout_537[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_547 (BatchN (None, 16, 16, 12)   48          average_pooling2d_34[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_546 (Activation)     (None, 16, 16, 12)   0           batch_normalization_547[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_569 (Conv2D)             (None, 16, 16, 12)   1296        activation_546[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_538 (Dropout)           (None, 16, 16, 12)   0           conv2d_569[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_512 (Concatenate)   (None, 16, 16, 24)   0           average_pooling2d_34[0][0]       \n",
            "                                                                 dropout_538[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_548 (BatchN (None, 16, 16, 24)   96          concatenate_512[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_547 (Activation)     (None, 16, 16, 24)   0           batch_normalization_548[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_570 (Conv2D)             (None, 16, 16, 12)   2592        activation_547[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_539 (Dropout)           (None, 16, 16, 12)   0           conv2d_570[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_513 (Concatenate)   (None, 16, 16, 36)   0           concatenate_512[0][0]            \n",
            "                                                                 dropout_539[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_549 (BatchN (None, 16, 16, 36)   144         concatenate_513[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_548 (Activation)     (None, 16, 16, 36)   0           batch_normalization_549[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_571 (Conv2D)             (None, 16, 16, 12)   3888        activation_548[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_540 (Dropout)           (None, 16, 16, 12)   0           conv2d_571[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_514 (Concatenate)   (None, 16, 16, 48)   0           concatenate_513[0][0]            \n",
            "                                                                 dropout_540[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_550 (BatchN (None, 16, 16, 48)   192         concatenate_514[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_549 (Activation)     (None, 16, 16, 48)   0           batch_normalization_550[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_572 (Conv2D)             (None, 16, 16, 12)   5184        activation_549[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_541 (Dropout)           (None, 16, 16, 12)   0           conv2d_572[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_515 (Concatenate)   (None, 16, 16, 60)   0           concatenate_514[0][0]            \n",
            "                                                                 dropout_541[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_551 (BatchN (None, 16, 16, 60)   240         concatenate_515[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_550 (Activation)     (None, 16, 16, 60)   0           batch_normalization_551[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_573 (Conv2D)             (None, 16, 16, 12)   6480        activation_550[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_542 (Dropout)           (None, 16, 16, 12)   0           conv2d_573[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_516 (Concatenate)   (None, 16, 16, 72)   0           concatenate_515[0][0]            \n",
            "                                                                 dropout_542[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_552 (BatchN (None, 16, 16, 72)   288         concatenate_516[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_551 (Activation)     (None, 16, 16, 72)   0           batch_normalization_552[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_574 (Conv2D)             (None, 16, 16, 12)   7776        activation_551[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_543 (Dropout)           (None, 16, 16, 12)   0           conv2d_574[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_517 (Concatenate)   (None, 16, 16, 84)   0           concatenate_516[0][0]            \n",
            "                                                                 dropout_543[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_553 (BatchN (None, 16, 16, 84)   336         concatenate_517[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_552 (Activation)     (None, 16, 16, 84)   0           batch_normalization_553[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_575 (Conv2D)             (None, 16, 16, 12)   9072        activation_552[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_544 (Dropout)           (None, 16, 16, 12)   0           conv2d_575[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_518 (Concatenate)   (None, 16, 16, 96)   0           concatenate_517[0][0]            \n",
            "                                                                 dropout_544[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_554 (BatchN (None, 16, 16, 96)   384         concatenate_518[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_553 (Activation)     (None, 16, 16, 96)   0           batch_normalization_554[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_576 (Conv2D)             (None, 16, 16, 12)   10368       activation_553[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_545 (Dropout)           (None, 16, 16, 12)   0           conv2d_576[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_519 (Concatenate)   (None, 16, 16, 108)  0           concatenate_518[0][0]            \n",
            "                                                                 dropout_545[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_555 (BatchN (None, 16, 16, 108)  432         concatenate_519[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_554 (Activation)     (None, 16, 16, 108)  0           batch_normalization_555[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_577 (Conv2D)             (None, 16, 16, 12)   11664       activation_554[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_546 (Dropout)           (None, 16, 16, 12)   0           conv2d_577[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_520 (Concatenate)   (None, 16, 16, 120)  0           concatenate_519[0][0]            \n",
            "                                                                 dropout_546[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_556 (BatchN (None, 16, 16, 120)  480         concatenate_520[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_555 (Activation)     (None, 16, 16, 120)  0           batch_normalization_556[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_578 (Conv2D)             (None, 16, 16, 12)   12960       activation_555[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_547 (Dropout)           (None, 16, 16, 12)   0           conv2d_578[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_521 (Concatenate)   (None, 16, 16, 132)  0           concatenate_520[0][0]            \n",
            "                                                                 dropout_547[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_557 (BatchN (None, 16, 16, 132)  528         concatenate_521[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_556 (Activation)     (None, 16, 16, 132)  0           batch_normalization_557[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_579 (Conv2D)             (None, 16, 16, 12)   14256       activation_556[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_548 (Dropout)           (None, 16, 16, 12)   0           conv2d_579[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_522 (Concatenate)   (None, 16, 16, 144)  0           concatenate_521[0][0]            \n",
            "                                                                 dropout_548[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_558 (BatchN (None, 16, 16, 144)  576         concatenate_522[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_557 (Activation)     (None, 16, 16, 144)  0           batch_normalization_558[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_580 (Conv2D)             (None, 16, 16, 12)   15552       activation_557[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_549 (Dropout)           (None, 16, 16, 12)   0           conv2d_580[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_523 (Concatenate)   (None, 16, 16, 156)  0           concatenate_522[0][0]            \n",
            "                                                                 dropout_549[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_559 (BatchN (None, 16, 16, 156)  624         concatenate_523[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_558 (Activation)     (None, 16, 16, 156)  0           batch_normalization_559[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_581 (Conv2D)             (None, 16, 16, 12)   1872        activation_558[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_550 (Dropout)           (None, 16, 16, 12)   0           conv2d_581[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_35 (AveragePo (None, 8, 8, 12)     0           dropout_550[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_560 (BatchN (None, 8, 8, 12)     48          average_pooling2d_35[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_559 (Activation)     (None, 8, 8, 12)     0           batch_normalization_560[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_582 (Conv2D)             (None, 8, 8, 12)     1296        activation_559[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_551 (Dropout)           (None, 8, 8, 12)     0           conv2d_582[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_524 (Concatenate)   (None, 8, 8, 24)     0           average_pooling2d_35[0][0]       \n",
            "                                                                 dropout_551[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_561 (BatchN (None, 8, 8, 24)     96          concatenate_524[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_560 (Activation)     (None, 8, 8, 24)     0           batch_normalization_561[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_583 (Conv2D)             (None, 8, 8, 12)     2592        activation_560[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_552 (Dropout)           (None, 8, 8, 12)     0           conv2d_583[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_525 (Concatenate)   (None, 8, 8, 36)     0           concatenate_524[0][0]            \n",
            "                                                                 dropout_552[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_562 (BatchN (None, 8, 8, 36)     144         concatenate_525[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_561 (Activation)     (None, 8, 8, 36)     0           batch_normalization_562[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_584 (Conv2D)             (None, 8, 8, 12)     3888        activation_561[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_553 (Dropout)           (None, 8, 8, 12)     0           conv2d_584[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_526 (Concatenate)   (None, 8, 8, 48)     0           concatenate_525[0][0]            \n",
            "                                                                 dropout_553[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_563 (BatchN (None, 8, 8, 48)     192         concatenate_526[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_562 (Activation)     (None, 8, 8, 48)     0           batch_normalization_563[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_585 (Conv2D)             (None, 8, 8, 12)     5184        activation_562[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_554 (Dropout)           (None, 8, 8, 12)     0           conv2d_585[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_527 (Concatenate)   (None, 8, 8, 60)     0           concatenate_526[0][0]            \n",
            "                                                                 dropout_554[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_564 (BatchN (None, 8, 8, 60)     240         concatenate_527[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_563 (Activation)     (None, 8, 8, 60)     0           batch_normalization_564[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_586 (Conv2D)             (None, 8, 8, 12)     6480        activation_563[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_555 (Dropout)           (None, 8, 8, 12)     0           conv2d_586[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_528 (Concatenate)   (None, 8, 8, 72)     0           concatenate_527[0][0]            \n",
            "                                                                 dropout_555[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_565 (BatchN (None, 8, 8, 72)     288         concatenate_528[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_564 (Activation)     (None, 8, 8, 72)     0           batch_normalization_565[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_587 (Conv2D)             (None, 8, 8, 12)     7776        activation_564[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_556 (Dropout)           (None, 8, 8, 12)     0           conv2d_587[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_529 (Concatenate)   (None, 8, 8, 84)     0           concatenate_528[0][0]            \n",
            "                                                                 dropout_556[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_566 (BatchN (None, 8, 8, 84)     336         concatenate_529[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_565 (Activation)     (None, 8, 8, 84)     0           batch_normalization_566[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_588 (Conv2D)             (None, 8, 8, 12)     9072        activation_565[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_557 (Dropout)           (None, 8, 8, 12)     0           conv2d_588[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_530 (Concatenate)   (None, 8, 8, 96)     0           concatenate_529[0][0]            \n",
            "                                                                 dropout_557[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_567 (BatchN (None, 8, 8, 96)     384         concatenate_530[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_566 (Activation)     (None, 8, 8, 96)     0           batch_normalization_567[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_589 (Conv2D)             (None, 8, 8, 12)     10368       activation_566[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_558 (Dropout)           (None, 8, 8, 12)     0           conv2d_589[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_531 (Concatenate)   (None, 8, 8, 108)    0           concatenate_530[0][0]            \n",
            "                                                                 dropout_558[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_568 (BatchN (None, 8, 8, 108)    432         concatenate_531[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_567 (Activation)     (None, 8, 8, 108)    0           batch_normalization_568[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_590 (Conv2D)             (None, 8, 8, 12)     11664       activation_567[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_559 (Dropout)           (None, 8, 8, 12)     0           conv2d_590[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_532 (Concatenate)   (None, 8, 8, 120)    0           concatenate_531[0][0]            \n",
            "                                                                 dropout_559[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_569 (BatchN (None, 8, 8, 120)    480         concatenate_532[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_568 (Activation)     (None, 8, 8, 120)    0           batch_normalization_569[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_591 (Conv2D)             (None, 8, 8, 12)     12960       activation_568[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_560 (Dropout)           (None, 8, 8, 12)     0           conv2d_591[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_533 (Concatenate)   (None, 8, 8, 132)    0           concatenate_532[0][0]            \n",
            "                                                                 dropout_560[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_570 (BatchN (None, 8, 8, 132)    528         concatenate_533[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_569 (Activation)     (None, 8, 8, 132)    0           batch_normalization_570[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_592 (Conv2D)             (None, 8, 8, 12)     14256       activation_569[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_561 (Dropout)           (None, 8, 8, 12)     0           conv2d_592[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_534 (Concatenate)   (None, 8, 8, 144)    0           concatenate_533[0][0]            \n",
            "                                                                 dropout_561[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_571 (BatchN (None, 8, 8, 144)    576         concatenate_534[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_570 (Activation)     (None, 8, 8, 144)    0           batch_normalization_571[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_593 (Conv2D)             (None, 8, 8, 12)     15552       activation_570[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_562 (Dropout)           (None, 8, 8, 12)     0           conv2d_593[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_535 (Concatenate)   (None, 8, 8, 156)    0           concatenate_534[0][0]            \n",
            "                                                                 dropout_562[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_572 (BatchN (None, 8, 8, 156)    624         concatenate_535[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_571 (Activation)     (None, 8, 8, 156)    0           batch_normalization_572[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_594 (Conv2D)             (None, 8, 8, 12)     1872        activation_571[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_563 (Dropout)           (None, 8, 8, 12)     0           conv2d_594[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_36 (AveragePo (None, 4, 4, 12)     0           dropout_563[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_573 (BatchN (None, 4, 4, 12)     48          average_pooling2d_36[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_572 (Activation)     (None, 4, 4, 12)     0           batch_normalization_573[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_595 (Conv2D)             (None, 4, 4, 12)     1296        activation_572[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_564 (Dropout)           (None, 4, 4, 12)     0           conv2d_595[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_536 (Concatenate)   (None, 4, 4, 24)     0           average_pooling2d_36[0][0]       \n",
            "                                                                 dropout_564[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_574 (BatchN (None, 4, 4, 24)     96          concatenate_536[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_573 (Activation)     (None, 4, 4, 24)     0           batch_normalization_574[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_596 (Conv2D)             (None, 4, 4, 12)     2592        activation_573[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_565 (Dropout)           (None, 4, 4, 12)     0           conv2d_596[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_537 (Concatenate)   (None, 4, 4, 36)     0           concatenate_536[0][0]            \n",
            "                                                                 dropout_565[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_575 (BatchN (None, 4, 4, 36)     144         concatenate_537[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_574 (Activation)     (None, 4, 4, 36)     0           batch_normalization_575[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_597 (Conv2D)             (None, 4, 4, 12)     3888        activation_574[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_566 (Dropout)           (None, 4, 4, 12)     0           conv2d_597[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_538 (Concatenate)   (None, 4, 4, 48)     0           concatenate_537[0][0]            \n",
            "                                                                 dropout_566[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_576 (BatchN (None, 4, 4, 48)     192         concatenate_538[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_575 (Activation)     (None, 4, 4, 48)     0           batch_normalization_576[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_598 (Conv2D)             (None, 4, 4, 12)     5184        activation_575[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_567 (Dropout)           (None, 4, 4, 12)     0           conv2d_598[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_539 (Concatenate)   (None, 4, 4, 60)     0           concatenate_538[0][0]            \n",
            "                                                                 dropout_567[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_577 (BatchN (None, 4, 4, 60)     240         concatenate_539[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_576 (Activation)     (None, 4, 4, 60)     0           batch_normalization_577[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_599 (Conv2D)             (None, 4, 4, 12)     6480        activation_576[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_568 (Dropout)           (None, 4, 4, 12)     0           conv2d_599[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_540 (Concatenate)   (None, 4, 4, 72)     0           concatenate_539[0][0]            \n",
            "                                                                 dropout_568[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_578 (BatchN (None, 4, 4, 72)     288         concatenate_540[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_577 (Activation)     (None, 4, 4, 72)     0           batch_normalization_578[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_600 (Conv2D)             (None, 4, 4, 12)     7776        activation_577[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_569 (Dropout)           (None, 4, 4, 12)     0           conv2d_600[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_541 (Concatenate)   (None, 4, 4, 84)     0           concatenate_540[0][0]            \n",
            "                                                                 dropout_569[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_579 (BatchN (None, 4, 4, 84)     336         concatenate_541[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_578 (Activation)     (None, 4, 4, 84)     0           batch_normalization_579[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_601 (Conv2D)             (None, 4, 4, 12)     9072        activation_578[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_570 (Dropout)           (None, 4, 4, 12)     0           conv2d_601[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_542 (Concatenate)   (None, 4, 4, 96)     0           concatenate_541[0][0]            \n",
            "                                                                 dropout_570[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_580 (BatchN (None, 4, 4, 96)     384         concatenate_542[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_579 (Activation)     (None, 4, 4, 96)     0           batch_normalization_580[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_602 (Conv2D)             (None, 4, 4, 12)     10368       activation_579[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_571 (Dropout)           (None, 4, 4, 12)     0           conv2d_602[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_543 (Concatenate)   (None, 4, 4, 108)    0           concatenate_542[0][0]            \n",
            "                                                                 dropout_571[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_581 (BatchN (None, 4, 4, 108)    432         concatenate_543[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_580 (Activation)     (None, 4, 4, 108)    0           batch_normalization_581[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_603 (Conv2D)             (None, 4, 4, 12)     11664       activation_580[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_572 (Dropout)           (None, 4, 4, 12)     0           conv2d_603[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_544 (Concatenate)   (None, 4, 4, 120)    0           concatenate_543[0][0]            \n",
            "                                                                 dropout_572[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_582 (BatchN (None, 4, 4, 120)    480         concatenate_544[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_581 (Activation)     (None, 4, 4, 120)    0           batch_normalization_582[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_604 (Conv2D)             (None, 4, 4, 12)     12960       activation_581[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_573 (Dropout)           (None, 4, 4, 12)     0           conv2d_604[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_545 (Concatenate)   (None, 4, 4, 132)    0           concatenate_544[0][0]            \n",
            "                                                                 dropout_573[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_583 (BatchN (None, 4, 4, 132)    528         concatenate_545[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_582 (Activation)     (None, 4, 4, 132)    0           batch_normalization_583[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_605 (Conv2D)             (None, 4, 4, 12)     14256       activation_582[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_574 (Dropout)           (None, 4, 4, 12)     0           conv2d_605[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_546 (Concatenate)   (None, 4, 4, 144)    0           concatenate_545[0][0]            \n",
            "                                                                 dropout_574[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_584 (BatchN (None, 4, 4, 144)    576         concatenate_546[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_583 (Activation)     (None, 4, 4, 144)    0           batch_normalization_584[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_606 (Conv2D)             (None, 4, 4, 12)     15552       activation_583[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_575 (Dropout)           (None, 4, 4, 12)     0           conv2d_606[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_547 (Concatenate)   (None, 4, 4, 156)    0           concatenate_546[0][0]            \n",
            "                                                                 dropout_575[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_585 (BatchN (None, 4, 4, 156)    624         concatenate_547[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_584 (Activation)     (None, 4, 4, 156)    0           batch_normalization_585[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_37 (AveragePo (None, 2, 2, 156)    0           activation_584[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_9 (Flatten)             (None, 624)          0           average_pooling2d_37[0][0]       \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 10)           6250        flatten_9[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 460,450\n",
            "Trainable params: 451,402\n",
            "Non-trainable params: 9,048\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ihOAWVYh6TCL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# determine Loss function and Optimizer\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ARcN6sC76TK7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1771
        },
        "outputId": "fb58ad04-d8b8-49fd-e30d-cdf29033aacc"
      },
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test))"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "50000/50000 [==============================] - 303s 6ms/step - loss: 1.5727 - acc: 0.4183 - val_loss: 1.5405 - val_acc: 0.4711\n",
            "Epoch 2/50\n",
            "19200/50000 [==========>...................] - ETA: 2:27 - loss: 1.2481 - acc: 0.5463"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 255s 5ms/step - loss: 1.1726 - acc: 0.5767 - val_loss: 1.1966 - val_acc: 0.6073\n",
            "Epoch 3/50\n",
            "45568/50000 [==========================>...] - ETA: 21s - loss: 0.9893 - acc: 0.6440"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 255s 5ms/step - loss: 0.9843 - acc: 0.6465 - val_loss: 2.6375 - val_acc: 0.4407\n",
            "Epoch 4/50\n",
            "50000/50000 [==============================] - 255s 5ms/step - loss: 0.8766 - acc: 0.6869 - val_loss: 1.2908 - val_acc: 0.6041\n",
            "Epoch 5/50\n",
            " 3328/50000 [>.............................] - ETA: 3:43 - loss: 0.8320 - acc: 0.7079"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 255s 5ms/step - loss: 0.7984 - acc: 0.7182 - val_loss: 1.2166 - val_acc: 0.6266\n",
            "Epoch 6/50\n",
            "39424/50000 [======================>.......] - ETA: 50s - loss: 0.7401 - acc: 0.7375"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 255s 5ms/step - loss: 0.7338 - acc: 0.7394 - val_loss: 1.0311 - val_acc: 0.6875\n",
            "Epoch 7/50\n",
            "50000/50000 [==============================] - 255s 5ms/step - loss: 0.6836 - acc: 0.7588 - val_loss: 1.3414 - val_acc: 0.6268\n",
            "Epoch 8/50\n",
            " 1792/50000 [>.............................] - ETA: 3:49 - loss: 0.6488 - acc: 0.7701"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 254s 5ms/step - loss: 0.6426 - acc: 0.7745 - val_loss: 1.0004 - val_acc: 0.7071\n",
            "Epoch 9/50\n",
            "38912/50000 [======================>.......] - ETA: 52s - loss: 0.6041 - acc: 0.7874"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 254s 5ms/step - loss: 0.5995 - acc: 0.7891 - val_loss: 0.7720 - val_acc: 0.7480\n",
            "Epoch 10/50\n",
            "50000/50000 [==============================] - 255s 5ms/step - loss: 0.5735 - acc: 0.7995 - val_loss: 0.7737 - val_acc: 0.7561\n",
            "Epoch 11/50\n",
            " 1536/50000 [..............................] - ETA: 3:52 - loss: 0.5385 - acc: 0.8060"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 255s 5ms/step - loss: 0.5404 - acc: 0.8110 - val_loss: 0.7623 - val_acc: 0.7556\n",
            "Epoch 12/50\n",
            "38528/50000 [======================>.......] - ETA: 54s - loss: 0.5184 - acc: 0.8197"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 255s 5ms/step - loss: 0.5176 - acc: 0.8194 - val_loss: 0.7461 - val_acc: 0.7790\n",
            "Epoch 13/50\n",
            "50000/50000 [==============================] - 255s 5ms/step - loss: 0.4923 - acc: 0.8273 - val_loss: 1.0505 - val_acc: 0.6915\n",
            "Epoch 14/50\n",
            " 1536/50000 [..............................] - ETA: 3:51 - loss: 0.4745 - acc: 0.8379"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 255s 5ms/step - loss: 0.4725 - acc: 0.8344 - val_loss: 1.0049 - val_acc: 0.7224\n",
            "Epoch 15/50\n",
            "38528/50000 [======================>.......] - ETA: 54s - loss: 0.4561 - acc: 0.8403"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 255s 5ms/step - loss: 0.4584 - acc: 0.8392 - val_loss: 1.0872 - val_acc: 0.7180\n",
            "Epoch 16/50\n",
            "50000/50000 [==============================] - 255s 5ms/step - loss: 0.4366 - acc: 0.8492 - val_loss: 0.9326 - val_acc: 0.7351\n",
            "Epoch 17/50\n",
            " 1536/50000 [..............................] - ETA: 3:52 - loss: 0.3966 - acc: 0.8659"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 254s 5ms/step - loss: 0.4287 - acc: 0.8504 - val_loss: 0.9666 - val_acc: 0.7354\n",
            "Epoch 18/50\n",
            "38528/50000 [======================>.......] - ETA: 54s - loss: 0.4033 - acc: 0.8594"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 254s 5ms/step - loss: 0.4088 - acc: 0.8575 - val_loss: 0.8194 - val_acc: 0.7720\n",
            "Epoch 19/50\n",
            "50000/50000 [==============================] - 254s 5ms/step - loss: 0.3961 - acc: 0.8628 - val_loss: 0.6118 - val_acc: 0.8078\n",
            "Epoch 20/50\n",
            " 1536/50000 [..............................] - ETA: 3:51 - loss: 0.3507 - acc: 0.8783"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 255s 5ms/step - loss: 0.3845 - acc: 0.8666 - val_loss: 0.6322 - val_acc: 0.8152\n",
            "Epoch 21/50\n",
            "38528/50000 [======================>.......] - ETA: 54s - loss: 0.3736 - acc: 0.8687"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 254s 5ms/step - loss: 0.3727 - acc: 0.8689 - val_loss: 0.8992 - val_acc: 0.7510\n",
            "Epoch 22/50\n",
            "50000/50000 [==============================] - 254s 5ms/step - loss: 0.3598 - acc: 0.8732 - val_loss: 0.7421 - val_acc: 0.7921\n",
            "Epoch 23/50\n",
            " 1536/50000 [..............................] - ETA: 3:51 - loss: 0.3290 - acc: 0.8835"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 254s 5ms/step - loss: 0.3506 - acc: 0.8783 - val_loss: 0.7076 - val_acc: 0.8027\n",
            "Epoch 24/50\n",
            "38528/50000 [======================>.......] - ETA: 54s - loss: 0.3418 - acc: 0.8806"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 255s 5ms/step - loss: 0.3422 - acc: 0.8814 - val_loss: 0.6068 - val_acc: 0.8271\n",
            "Epoch 25/50\n",
            "50000/50000 [==============================] - 255s 5ms/step - loss: 0.3329 - acc: 0.8856 - val_loss: 0.5997 - val_acc: 0.8310\n",
            "Epoch 26/50\n",
            " 1536/50000 [..............................] - ETA: 3:52 - loss: 0.3597 - acc: 0.8724"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 255s 5ms/step - loss: 0.3294 - acc: 0.8834 - val_loss: 0.6861 - val_acc: 0.8022\n",
            "Epoch 27/50\n",
            "38528/50000 [======================>.......] - ETA: 54s - loss: 0.3083 - acc: 0.8927"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 254s 5ms/step - loss: 0.3120 - acc: 0.8914 - val_loss: 0.8498 - val_acc: 0.7808\n",
            "Epoch 28/50\n",
            "50000/50000 [==============================] - 255s 5ms/step - loss: 0.3101 - acc: 0.8911 - val_loss: 0.7076 - val_acc: 0.8066\n",
            "Epoch 29/50\n",
            " 1536/50000 [..............................] - ETA: 3:51 - loss: 0.2871 - acc: 0.8984"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 255s 5ms/step - loss: 0.3032 - acc: 0.8937 - val_loss: 0.8469 - val_acc: 0.7751\n",
            "Epoch 30/50\n",
            "38528/50000 [======================>.......] - ETA: 54s - loss: 0.2892 - acc: 0.8972"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 255s 5ms/step - loss: 0.2923 - acc: 0.8956 - val_loss: 0.6944 - val_acc: 0.8163\n",
            "Epoch 31/50\n",
            "50000/50000 [==============================] - 254s 5ms/step - loss: 0.2896 - acc: 0.8973 - val_loss: 0.6047 - val_acc: 0.8358\n",
            "Epoch 32/50\n",
            " 1536/50000 [..............................] - ETA: 3:52 - loss: 0.2511 - acc: 0.9180"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 255s 5ms/step - loss: 0.2854 - acc: 0.9002 - val_loss: 0.6256 - val_acc: 0.8290\n",
            "Epoch 33/50\n",
            "38528/50000 [======================>.......] - ETA: 54s - loss: 0.2697 - acc: 0.9058"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 255s 5ms/step - loss: 0.2713 - acc: 0.9051 - val_loss: 0.6858 - val_acc: 0.8188\n",
            "Epoch 34/50\n",
            "50000/50000 [==============================] - 255s 5ms/step - loss: 0.2700 - acc: 0.9040 - val_loss: 0.6628 - val_acc: 0.8220\n",
            "Epoch 35/50\n",
            " 1536/50000 [..............................] - ETA: 3:51 - loss: 0.2252 - acc: 0.9199"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 254s 5ms/step - loss: 0.2608 - acc: 0.9074 - val_loss: 0.8016 - val_acc: 0.8037\n",
            "Epoch 36/50\n",
            "38528/50000 [======================>.......] - ETA: 54s - loss: 0.2516 - acc: 0.9096"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 254s 5ms/step - loss: 0.2550 - acc: 0.9087 - val_loss: 0.7442 - val_acc: 0.8086\n",
            "Epoch 37/50\n",
            "50000/50000 [==============================] - 255s 5ms/step - loss: 0.2535 - acc: 0.9100 - val_loss: 0.9718 - val_acc: 0.7658\n",
            "Epoch 38/50\n",
            " 1536/50000 [..............................] - ETA: 3:52 - loss: 0.2484 - acc: 0.9154"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 255s 5ms/step - loss: 0.2480 - acc: 0.9115 - val_loss: 0.8347 - val_acc: 0.7940\n",
            "Epoch 39/50\n",
            "38528/50000 [======================>.......] - ETA: 54s - loss: 0.2373 - acc: 0.9150"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 255s 5ms/step - loss: 0.2414 - acc: 0.9132 - val_loss: 0.5908 - val_acc: 0.8417\n",
            "Epoch 40/50\n",
            "50000/50000 [==============================] - 254s 5ms/step - loss: 0.2324 - acc: 0.9168 - val_loss: 0.6466 - val_acc: 0.8350\n",
            "Epoch 41/50\n",
            " 1536/50000 [..............................] - ETA: 3:51 - loss: 0.2195 - acc: 0.9238"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 255s 5ms/step - loss: 0.2328 - acc: 0.9172 - val_loss: 0.8140 - val_acc: 0.8110\n",
            "Epoch 42/50\n",
            "38528/50000 [======================>.......] - ETA: 54s - loss: 0.2211 - acc: 0.9228"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 255s 5ms/step - loss: 0.2256 - acc: 0.9207 - val_loss: 1.0533 - val_acc: 0.7727\n",
            "Epoch 43/50\n",
            "50000/50000 [==============================] - 255s 5ms/step - loss: 0.2239 - acc: 0.9211 - val_loss: 0.6465 - val_acc: 0.8328\n",
            "Epoch 44/50\n",
            " 1536/50000 [..............................] - ETA: 3:50 - loss: 0.2030 - acc: 0.9362"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 255s 5ms/step - loss: 0.2189 - acc: 0.9209 - val_loss: 0.7253 - val_acc: 0.8137\n",
            "Epoch 45/50\n",
            "38528/50000 [======================>.......] - ETA: 54s - loss: 0.2167 - acc: 0.9225"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 255s 5ms/step - loss: 0.2204 - acc: 0.9211 - val_loss: 0.6608 - val_acc: 0.8378\n",
            "Epoch 46/50\n",
            "50000/50000 [==============================] - 254s 5ms/step - loss: 0.2071 - acc: 0.9268 - val_loss: 0.7902 - val_acc: 0.8130\n",
            "Epoch 47/50\n",
            " 1536/50000 [..............................] - ETA: 3:50 - loss: 0.1761 - acc: 0.9434"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 255s 5ms/step - loss: 0.2064 - acc: 0.9269 - val_loss: 0.6501 - val_acc: 0.8430\n",
            "Epoch 48/50\n",
            "38528/50000 [======================>.......] - ETA: 54s - loss: 0.1962 - acc: 0.9298"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 254s 5ms/step - loss: 0.2008 - acc: 0.9280 - val_loss: 0.7638 - val_acc: 0.8201\n",
            "Epoch 49/50\n",
            "50000/50000 [==============================] - 254s 5ms/step - loss: 0.1986 - acc: 0.9283 - val_loss: 0.5937 - val_acc: 0.8537\n",
            "Epoch 50/50\n",
            " 1536/50000 [..............................] - ETA: 3:51 - loss: 0.2040 - acc: 0.9225"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 255s 5ms/step - loss: 0.1974 - acc: 0.9296 - val_loss: 0.5955 - val_acc: 0.8560\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f947004be80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "metadata": {
        "id": "ThNt8bzuj6NI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "ae0ff3aa-85f9-4f6e-b3c1-19f02402728b"
      },
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "score = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 23s 2ms/step\n",
            "Test loss: 0.5954634487867355\n",
            "Test accuracy: 0.856\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UgfcV_SPelza",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f1d40439-a50b-4a97-9270-825bda7c7dc4"
      },
      "cell_type": "code",
      "source": [
        "# Save the trained weights in to .h5 format\n",
        "model.save_weights(\"DNST_model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nnt7rLddezuI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('DNST_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}